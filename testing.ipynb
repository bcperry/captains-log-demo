{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a34b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# Load environment variables from .azure/captainslog/.env\n",
    "load_dotenv('.azure/captainslog/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1263cac3",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Region: usgovvirginia\n",
      "Speech Endpoint: https://cog-speechg5azofxckevgi.cognitiveservices.azure.us/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Get the environment variables\n",
    "speech_key = os.getenv('AZURE_SPEECH_KEY')\n",
    "speech_region = os.getenv('AZURE_SPEECH_REGION')\n",
    "speech_endpoint = os.getenv('AZURE_SPEECH_ENDPOINT')\n",
    "\n",
    "stt_api = 'api.cognitive.microsoft.us'\n",
    "\n",
    "# Print the environment variables to verify they are loaded correctly\n",
    "# print(f\"Speech Key: {speech_key}\")\n",
    "print(f\"Speech Region: {speech_region}\")\n",
    "print(f\"Speech Endpoint: {speech_endpoint}\")\n",
    "\n",
    "# Define the endpoint URL\n",
    "url = f\"https://{speech_region}.{stt_api}/speech/recognition/conversation/cognitiveservices/v1\"\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'language': 'en-US',\n",
    "    'format': 'detailed'\n",
    "}\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'audio/wav'\n",
    "}\n",
    "\n",
    "# # Read the audio file\n",
    "# with open(file, 'rb') as audio_file:\n",
    "#     audio_data = audio_file.read()\n",
    "\n",
    "# # Make the POST request\n",
    "# response = requests.post(url, params=params, headers=headers, data=audio_data)\n",
    "\n",
    "# # Print the response\n",
    "# print(response.status_code)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210a291c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "usGovEndpoint = \"wss://usgovvirginia.stt.speech.azure.us\"\n",
    "speech_config = speechsdk.SpeechConfig(endpoint=usGovEndpoint, subscription=speech_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6413c293",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# def recognize_from_microphone():\n",
    "#      # This example requires environment variables named \"SPEECH_KEY\" and \"ENDPOINT\"\n",
    "#      # Replace with your own subscription key and endpoint, the endpoint is like : \"https://YourServiceRegion.api.cognitive.microsoft.com\"\n",
    "#     speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "#     audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "#     speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "#     print(\"Speak into your microphone.\")\n",
    "#     speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "#     if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "#         print(\"Recognized: {}\".format(speech_recognition_result.text))\n",
    "#     elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "#         print(\"No speech could be recognized: {}\".format(speech_recognition_result.no_match_details))\n",
    "#     elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "#         cancellation_details = speech_recognition_result.cancellation_details\n",
    "#         print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "#         if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "#             print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "#             print(\"Did you set the speech resource key and endpoint values?\")\n",
    "\n",
    "# # recognize_from_microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8359587",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "\n",
    "def split_audio(input_file):\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "\n",
    "    # Define the chunk length (e.g., 30 seconds)\n",
    "    chunk_duration_ms = 30 * 1000 # in milliseconds\n",
    "\n",
    "    # Calculate number of chunks\n",
    "    num_chunks = (len(audio) // chunk_duration_ms)+1\n",
    "\n",
    "    # Split the audio file into chunks\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_duration_ms\n",
    "        end = (i + 1) * chunk_duration_ms\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def transcribe(filename: str):\n",
    "    # Split audio file into chunks\n",
    "    audio_chunks = split_audio(filename)\n",
    "    print(\"Number of audio chunks: {}\".format(len(audio_chunks)))\n",
    "    print(f\"Transcribing {len(audio_chunks)} audio chunks from {filename}\")\n",
    "    print(f\"Audio duration: {len(AudioSegment.from_file(filename)) / 1000} seconds\")\n",
    "\n",
    "    full_transcription = \"\"\n",
    "    # Transcribe each chunk\n",
    "    for chunk in audio_chunks:\n",
    "\n",
    "        # Create a temporary file to store the audio chunk\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio_file:\n",
    "            chunk.export(temp_audio_file.name, format=\"wav\")\n",
    "\n",
    "            audio_config = speechsdk.audio.AudioConfig(filename=temp_audio_file.name)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "            \n",
    "            transcription = speech_recognizer.recognize_once()\n",
    "            print(f\"Transcription for chunk: {transcription.json}\")\n",
    "\n",
    "        # return transcription\n",
    "            if isinstance(transcription, dict):\n",
    "                text = transcription['text']\n",
    "            else:\n",
    "                text = transcription.text\n",
    "            print(text)\n",
    "            full_transcription = full_transcription + text\n",
    "            \n",
    "        # Close and Delete the temporary audio file\n",
    "        temp_audio_file.close()\n",
    "        # os.unlink(temp_audio_file.name)\n",
    "    return full_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6529474e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio chunks: 1\n",
      "Transcribing 1 audio chunks from C:\\Users\\blaineperry\\Downloads\\output (1).wav\n",
      "Audio duration: 1.238 seconds\n",
      "Transcription for chunk: {\"Id\":\"ef07469bbd0f4b849a763df9bc22b88e\",\"RecognitionStatus\":\"Success\",\"DisplayText\":\"Download me.\",\"Offset\":700000,\"Duration\":10900000,\"Channel\":0}\n",
      "Download me.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Download me.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r\"C:\\Users\\blaineperry\\Downloads\\output (1).wav\"\n",
    "# file = r\"C:\\Users\\blaineperry\\Downloads\\MSFT_OSS Azure AI Services discussion [In-person]-20250306_125903-Meeting Recording.mp4\"\n",
    "# file = r\"C:\\Users\\BLAINE~1\\AppData\\Local\\Temp\\tmpqt2h_ugu.wav\"\n",
    "# file = r\"C:\\Users\\blaineperry\\Downloads\\test.mp3\"\n",
    "# transcribe(file)\n",
    "transcription = transcribe(file)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af98bf6e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file: C:\\Users\\blaineperry\\Downloads\\output (1).wav, File extension: wav\n",
      "Created 1 chunks of 30 seconds each\n"
     ]
    }
   ],
   "source": [
    "# import required modules\n",
    "\n",
    "\n",
    "# assign files\n",
    "filename = r\"C:\\Users\\blaineperry\\Downloads\\test.mp3\"\n",
    "filename = file\n",
    "output_file = \"result.wav\"\n",
    "\n",
    "# get the filetype from the input file text\n",
    "file_extension = path.splitext(filename)[1].lower()[1:]\n",
    "print(f\"Input file: {filename}, File extension: {file_extension}\")\n",
    "# convert mp3 file to wav file\n",
    "sound = AudioSegment.from_file(filename, file_extension)\n",
    "# Split audio into 30-second chunks\n",
    "chunk_duration_ms = 30 * 1000  # 30 seconds in milliseconds\n",
    "chunks = []\n",
    "\n",
    "for i in range(0, len(sound), chunk_duration_ms):\n",
    "    chunk = sound[i:i + chunk_duration_ms]\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks of 30 seconds each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757c85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file as a bytes IO object\n",
    "with open(file, 'rb') as f:\n",
    "    audio_bytes = f.read()\n",
    "\n",
    "# Create a BytesIO object from the audio data\n",
    "from io import BytesIO\n",
    "audio_io = BytesIO(audio_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a68a14a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio chunks: 1\n",
      "Transcribing 1 audio chunks from <_io.BytesIO object at 0x00000246CB5579C0>\n"
     ]
    },
    {
     "ename": "CouldntDecodeError",
     "evalue": "Decoding failed. ffmpeg returned error code: 3199971767\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 7.1.1-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\r\n  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      59. 39.100 / 59. 39.100\r\n  libavcodec     61. 19.101 / 61. 19.101\r\n  libavformat    61.  7.100 / 61.  7.100\r\n  libavdevice    61.  3.100 / 61.  3.100\r\n  libavfilter    10.  4.100 / 10.  4.100\r\n  libswscale      8.  3.100 /  8.  3.100\r\n  libswresample   5.  3.100 /  5.  3.100\r\n  libpostproc    58.  3.100 / 58.  3.100\r\n[cache @ 00000272aa88ee40] Statistics, cache hits:0 cache misses:0\r\n[in#0 @ 00000272aa88e500] Error opening input: Invalid data found when processing input\r\nError opening input file cache:pipe:0.\r\nError opening input files: Invalid data found when processing input\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCouldntDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m transcription = \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_io\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m transcription\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtranscribe\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of audio chunks: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(audio_chunks)))\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTranscribing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(audio_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m audio chunks from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAudio duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mAudioSegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m full_transcription = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Transcribe each chunk\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\blaineperry\\git\\captains-log-demo\\.venv\\Lib\\site-packages\\pydub\\audio_segment.py:773\u001b[39m, in \u001b[36mAudioSegment.from_file\u001b[39m\u001b[34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m close_file:\n\u001b[32m    772\u001b[39m         file.close()\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CouldntDecodeError(\n\u001b[32m    774\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDecoding failed. ffmpeg returned error code: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOutput from ffmpeg/avlib:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    775\u001b[39m             p.returncode, p_err.decode(errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m) ))\n\u001b[32m    777\u001b[39m p_out = \u001b[38;5;28mbytearray\u001b[39m(p_out)\n\u001b[32m    778\u001b[39m fix_wav_headers(p_out)\n",
      "\u001b[31mCouldntDecodeError\u001b[39m: Decoding failed. ffmpeg returned error code: 3199971767\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 7.1.1-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\r\n  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\r\n  libavutil      59. 39.100 / 59. 39.100\r\n  libavcodec     61. 19.101 / 61. 19.101\r\n  libavformat    61.  7.100 / 61.  7.100\r\n  libavdevice    61.  3.100 / 61.  3.100\r\n  libavfilter    10.  4.100 / 10.  4.100\r\n  libswscale      8.  3.100 /  8.  3.100\r\n  libswresample   5.  3.100 /  5.  3.100\r\n  libpostproc    58.  3.100 / 58.  3.100\r\n[cache @ 00000272aa88ee40] Statistics, cache hits:0 cache misses:0\r\n[in#0 @ 00000272aa88e500] Error opening input: Invalid data found when processing input\r\nError opening input file cache:pipe:0.\r\nError opening input files: Invalid data found when processing input\r\n"
     ]
    }
   ],
   "source": [
    "transcription = transcribe(audio_io)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "\n",
    "# Create a named temporary file and write the BytesIO object to it\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "    temp_file.write(audio_io.getvalue())\n",
    "    temp_filename = temp_file.name\n",
    "\n",
    "print(f\"Audio data written to temporary file: {temp_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe343a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
